{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import keras.backend.tensorflow_backend as tb\n",
    "tb._SYMBOLIC_SCOPE.value = True\n",
    "\n",
    "\n",
    "import time\n",
    "import json\n",
    "import mysql.connector\n",
    "from SocialProcessor import SocialProcessor\n",
    "\n",
    "import vk_api\n",
    "import threading\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoppableThread(threading.Thread):\n",
    "    \"\"\"\n",
    "    Thread class with a stop() method. The thread itself has to check\n",
    "    regularly for the stopped() condition.\n",
    "    \n",
    "    \"\"\"\n",
    "    func = None\n",
    "    args = {}\n",
    "\n",
    "    def __init__(self,  *args, **kwargs):\n",
    "        super(StoppableThread, self).__init__(*args, **kwargs)\n",
    "        self._stop_event = threading.Event()\n",
    "\n",
    "    def stop(self):\n",
    "        self._stop_event.set()\n",
    "\n",
    "    def stopped(self):\n",
    "        return self._stop_event.is_set()\n",
    "    \n",
    "    def run(self):\n",
    "        self.args['thread'] = self\n",
    "        self.func(**self.args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_path = 'keras-facenet-master/model/keras/model/facenet_keras.h5'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aunt_vk():\n",
    "    return input(), True\n",
    "\n",
    "\n",
    "def capt_vk(captcha):\n",
    "    print(captcha.get_url())\n",
    "    inp = input()\n",
    "    captcha.try_again(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {}\n",
    "with open('credentials.json', 'r') as file:\n",
    "    credentials = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vk_session = vk_api.VkApi(credentials['login'], credentials['password'], auth_handler=aunt_vk, captcha_handler=capt_vk)\n",
    "vk_session.auth()\n",
    "\n",
    "api = vk_session.get_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performVkProcessing(delay=0, count=100, thread=False):\n",
    "    conn = mysql.connector.connect(user='face', host=\"localhost\", password=\"Hr3mI3PM5JlFWrub\", database='global_scrape', port=8889, collation=\"utf8mb4_general_ci\")\n",
    "    processor = SocialProcessor(conn, model, prefix='/Users/aleksandrdremov/PycharmProjects/GlobalScraper/')\n",
    "    time.sleep(delay)\n",
    "    while count>0:\n",
    "        if type(thread) != type(False):\n",
    "            if thread.stopped():\n",
    "                break\n",
    "        task = processor.getTask()\n",
    "        user_id = task[0]\n",
    "        query_id = task[-1]\n",
    "        processor.delTask(query_id)\n",
    "        \n",
    "        processor.processVkUser(api, user_id)\n",
    "        count-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea9a3805b2c44189ff3e84991a59b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=634.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "performVkProcessing(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "threading.active_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1707aacd96994bfe86d869267330386e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adf1ec1e4204ddca070c53923483315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7364c5def84bb99e947ce2975bdc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 410, in __stage2\n",
      "    out = self._rnet.predict(tempimg1)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 493, in call\n",
      "    (len(args), len(list(self.signature.input_arg))))\n",
      "ValueError: Arguments and signature arguments do not match. got: 29, expected: 30 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0908653a7e64f598d50ba89c98e5533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=569.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdab2a084773490289bd8a1c1adcba37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=143.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c76fad5a4f4e4fb82f5c41f0645959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf98a1c86ec0497bb61dac690e771e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 466, in __stage3\n",
      "    out = self._onet.predict(tempimg1)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 493, in call\n",
      "    (len(args), len(list(self.signature.input_arg))))\n",
      "ValueError: Arguments and signature arguments do not match. got: 574, expected: 575 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01fde06542947fdad74a2b3b0e6433b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cd86ea9d5e447f8c6095880c9ad91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b926891d9d6488e9dc8c400e3b7cae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 342, in __stage1\n",
      "    out = self._pnet.predict(img_y)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1456, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 378, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 3011, in function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3773, in function\n",
      "    return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3670, in __init__\n",
      "    base_graph=source_graph)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/lift_to_graph.py\", line 300, in lift_to_graph\n",
      "    for external_capture, internal_capture in captures:\n",
      "RuntimeError: OrderedDict mutated during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 342, in __stage1\n",
      "    out = self._pnet.predict(img_y)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 493, in call\n",
      "    (len(args), len(list(self.signature.input_arg))))\n",
      "ValueError: Arguments and signature arguments do not match. got: 25, expected: 26 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 410, in __stage2\n",
      "    out = self._rnet.predict(tempimg1)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1456, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 378, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 3011, in function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3773, in function\n",
      "    return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3670, in __init__\n",
      "    base_graph=source_graph)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/lift_to_graph.py\", line 300, in lift_to_graph\n",
      "    for external_capture, internal_capture in captures:\n",
      "RuntimeError: OrderedDict mutated during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190014481:\n",
      "Added 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67a4452441e4fc6a6aba61c613e9cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=198.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 466, in __stage3\n",
      "    out = self._onet.predict(tempimg1)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1456, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 378, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 3011, in function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3773, in function\n",
      "    return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3670, in __init__\n",
      "    base_graph=source_graph)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/lift_to_graph.py\", line 300, in lift_to_graph\n",
      "    for external_capture, internal_capture in captures:\n",
      "RuntimeError: OrderedDict mutated during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437087273:\n",
      "Added 7 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc00d5533fa4720b6ad31b2621372c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 342, in __stage1\n",
      "    out = self._pnet.predict(img_y)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1456, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 378, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 3011, in function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3773, in function\n",
      "    return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3670, in __init__\n",
      "    base_graph=source_graph)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/lift_to_graph.py\", line 300, in lift_to_graph\n",
      "    for external_capture, internal_capture in captures:\n",
      "RuntimeError: OrderedDict mutated during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 466, in __stage3\n",
      "    out = self._onet.predict(tempimg1)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1456, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 378, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 3011, in function\n",
      "    **kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3773, in function\n",
      "    return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3670, in __init__\n",
      "    base_graph=source_graph)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/lift_to_graph.py\", line 300, in lift_to_graph\n",
      "    for external_capture, internal_capture in captures:\n",
      "RuntimeError: OrderedDict mutated during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-bdde2ce43cb7>\", line 22, in run\n",
      "    self.func(**self.args)\n",
      "  File \"<ipython-input-7-c1df61346120>\", line 14, in performVkProcessing\n",
      "    processor.processVkUser(api, user_id)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 89, in processVkUser\n",
      "    faces, links = self.getFacesFromLinks(photo_links[:self.limit])\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/SocialProcessor.py\", line 58, in getFacesFromLinks\n",
      "    faces_tmp = face_obj.load_and_align_image(margin=20)\n",
      "  File \"/Users/aleksandrdremov/PycharmProjects/GlobalScraper/FaceLoader.py\", line 83, in load_and_align_image\n",
      "    faces = detector.detect_faces(img)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
      "    result = stage(img, result[0], result[1])\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/mtcnn/mtcnn.py\", line 342, in __stage1\n",
      "    out = self._pnet.predict(img_y)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/keras/engine/training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/Users/aleksandrdremov/anaconda3/envs/FaceScrape/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 493, in call\n",
      "    (len(args), len(list(self.signature.input_arg))))\n",
      "ValueError: Arguments and signature arguments do not match. got: 16, expected: 17 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "217073708:\n",
      "Added 206 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87140eda036458b8624a00bdfebccba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "104283699:\n",
      "Added 35 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb205fec5f5b4bac87c017fc3096876d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "219910198:\n",
      "Added 1 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b61e044178f4a6fae8caddd36970c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "140324922:\n",
      "Added 15 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26f182da0894568ab30a3abc967794a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "126730302:\n",
      "Added 41 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dbadfc36f341259adc9c0aefe69659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_num = 10\n",
    "limits = 10\n",
    "step = 1.5\n",
    "params = [(i*step, limits) for i in range(t_num)]\n",
    "for args in params:\n",
    "    x = StoppableThread()\n",
    "    x.func = performVkProcessing\n",
    "    args = {\"delay\": args[0], \"count\": args[1]}\n",
    "    x.args = args\n",
    "    x.start()\n",
    "    threads.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "threading.active_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i.isAlive() for i in threads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceScrape",
   "language": "python",
   "name": "facescrape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}